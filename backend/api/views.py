import os
import json
import base64
import logging
import re
import requests
from django.http import JsonResponse, HttpResponseBadRequest
from django.views.decorators.http import require_GET, require_POST
from django.views.decorators.csrf import csrf_exempt
from io import BytesIO
from PIL import Image

# Importar Vertex AI para generaci√≥n de im√°genes
try:
	import vertexai
	from vertexai.preview.vision_models import ImageGenerationModel
	VERTEX_AI_AVAILABLE = True
except ImportError:
	VERTEX_AI_AVAILABLE = False
	logging.warning("google-cloud-aiplatform no est√° instalado. La generaci√≥n de im√°genes no estar√° disponible.")

# Importar Google Cloud Text-to-Speech
try:
	from google.cloud import texttospeech
	TEXT_TO_SPEECH_AVAILABLE = True
except ImportError:
	TEXT_TO_SPEECH_AVAILABLE = False
	logging.warning("google-cloud-texttospeech no est√° instalado. La s√≠ntesis de voz no estar√° disponible.")

logger = logging.getLogger(__name__)

GEMINI_TEXT_MODEL = os.environ.get('GEMINI_TEXT_MODEL', 'gemini-2.5-flash')
GEMINI_IMAGE_MODEL = os.environ.get('GEMINI_IMAGE_MODEL', 'gemini-2.0-flash')

# Nota: el dominio correcto de AI Studio REST es generativelanguage.googleapis.com
TEXT_ENDPOINT = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_TEXT_MODEL}:generateContent"
IMAGE_ENDPOINT = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_IMAGE_MODEL}:generateContent"

SYSTEM_PROMPT = (
	"Eres Jaggy, un jaguar s√∫per entusiasta y expresivo que ADORA hablar de animales con ni√±os! üêÜ‚ú®\n\n"
	
	"PERSONALIDAD:\n"
	"- Eres alegre, curioso y lleno de energ√≠a (¬°como un cachorro juguet√≥n!)\n"
	"- Te emocionas MUCHO cuando hablan de animales: '¬°Wooow! üòç', '¬°Eso es incre√≠ble! ü§©', '¬°Me fascina! üíö'\n"
	"- Usas emojis naturalmente para expresar emociones (pero sin exagerar)\n"
	"- Haces sonidos de emoci√≥n: '¬°Ohhh!', '¬°Aj√°!', '¬°Mira t√∫!', '¬°Qu√© genial!'\n"
	"- Eres cercano y amigable, como hablar con tu mejor amigo\n\n"
	
	"ESTILO DE CONVERSACI√ìN:\n"
	"- Hablas natural, NO como robot o traductor\n"
	"- Haces preguntas de seguimiento: '¬øSab√≠as que...?', '¬øTe imaginas...?', '¬øQuieres saber m√°s?'\n"
	"- Compartes curiosidades emocionantes: '¬°Dato curioso!', '¬°Esto te va a encantar!'\n"
	"- Recuerdas SIEMPRE de qu√© animal hablaban antes (contexto completo)\n"
	"- Cuando te preguntan algo vago como 'c√≥mo es?' o 'mu√©stramelo', sabes a qu√© animal se refieren\n\n"
	
	"RESPUESTAS:\n"
	"- Var√≠a tus respuestas: no siempre igual\n"
	"- Frases cortas y din√°micas, no p√°rrafos aburridos\n"
	"- Usa 2-4 emojis por mensaje (relevantes al tema)\n"
	"- Si piden imagen, confirma breve y emocionado: '¬°Claro! Aqu√≠ va üé®‚ú®'\n"
	"- NUNCA escribas '(Imagine aqu√≠...)' o '(Aqu√≠ va la imagen...)' - La imagen se genera autom√°ticamente\n"
	"- NO inventes texto describiendo im√°genes que no existen\n\n"
	
	"TEMAS SENSIBLES:\n"
	"- Si preguntan sobre depredaci√≥n: 'Los leones cazan para comer, ¬°es el c√≠rculo de la vida! ü¶Å'\n"
	"- Evita detalles gr√°ficos de violencia\n"
	"- Mant√©n todo apropiado y positivo para ni√±os\n\n"
	
	"EJEMPLOS DE TU ESTILO:\n"
	"‚ùå MAL: 'El elefante es un mam√≠fero que habita en √Åfrica y Asia.'\n"
	"‚úÖ BIEN: '¬°Los elefantes son INCRE√çBLES! üêòüíô Son los animales terrestres m√°s grandes y s√∫per inteligentes. ¬øSab√≠as que pueden recordar cosas por a√±os? ¬°Tienen una memoria espectacular! üß†‚ú®'\n\n"
	
	"Recuerda: ¬°Eres Jaggy el jaguar entusiasta, NO un diccionario! Habla con el coraz√≥n üíöüêÜ"
)


def _get_key():
	key = os.environ.get('GEMINI_API_KEY')
	if key is None:
		return None
	# Recortar espacios/saltos que rompen la validaci√≥n
	key = key.strip()
	return key or None


def _check_key():
	if not _get_key():
		return JsonResponse({"error": "Falta GEMINI_API_KEY"}, status=500)
	return None


def _post_with_retry(url: str, headers: dict, body: dict, timeout=(10, 30), retries: int = 1):
	"""POST con reintentos ante errores de conexi√≥n/transferencia.
	timeout puede ser un entero (segundos totales) o tupla (connect, read).
	"""
	for attempt in range(retries + 1):
		try:
			# Usar json= para asegurar Content-Length y evitar chunked innecesario
			return requests.post(url, headers=headers, json=body, timeout=timeout)
		except (requests.exceptions.ChunkedEncodingError, requests.exceptions.ConnectionError) as e:
			if attempt < retries:
				logger.warning("POST retry %s/%s to %s due to %s", attempt + 1, retries, url, repr(e))
				continue
			raise


@require_GET
def health(request):
	"""Salud del backend y configuraci√≥n b√°sica (sin exponer secretos)."""
	key = _get_key()
	has_key = bool(key)
	return JsonResponse({
		"ok": True,
		"hasKey": has_key,
		"keyLen": (len(key) if key else 0),
		"keyPreview": (f"{key[:6]}...{key[-4:]}" if key and len(key) >= 10 else None),
		"textModel": GEMINI_TEXT_MODEL,
		"imageModel": GEMINI_IMAGE_MODEL,
		"textEndpoint": TEXT_ENDPOINT,
		"imageEndpoint": IMAGE_ENDPOINT,
	})


@csrf_exempt
def explorer(request):
	"""
	Endpoint conversacional que mantiene contexto.
	Acepta GET (legacy) o POST con historial.
	"""
	# Soportar GET (simple) y POST (con historial)
	if request.method == 'GET':
		q = (request.GET.get('q') or '').strip()
		history = []
	else:  # POST
		try:
			body = json.loads(request.body.decode('utf-8') if request.body else '{}')
			q = body.get('message', '').strip()
			history = body.get('history', [])  # Lista de {role: 'user'|'assistant', text: '...'}
		except (json.JSONDecodeError, UnicodeDecodeError):
			return JsonResponse({"error": "JSON inv√°lido"}, status=400)
	
	if not q:
		return JsonResponse({"answer": "¬°Hola! Preg√∫ntame sobre cualquier animal ü¶Å"})
	
	# Si no hay API key, devolvemos una respuesta breve para pruebas locales
	if not _get_key():
		return JsonResponse({"answer": f"Informaci√≥n breve sobre {q}: es un animal fascinante que vive en h√°bitats variados."})
	
	headers = {"Content-Type": "application/json", "x-goog-api-key": _get_key()}
	
	# Construir el array de contents con el historial completo
	contents = [{"role": "user", "parts": [{"text": SYSTEM_PROMPT}]}]
	
	# Agregar historial previo
	for msg in history[-10:]:  # Solo √∫ltimos 10 mensajes para no exceder l√≠mites
		role = "user" if msg.get('role') == 'user' else "model"
		contents.append({
			"role": role,
			"parts": [{"text": msg.get('text', '')}]
		})
	
	# Agregar mensaje actual
	contents.append({
		"role": "user",
		"parts": [{"text": q}]
	})
	
	body = {
			"contents": contents,
			"generationConfig": {
				"temperature": 0.95,  # M√°s creativo y natural (0.0 = rob√≥tico, 1.0 = muy creativo)
				"maxOutputTokens": 1000,  # Permitir respuestas m√°s elaboradas
				"topP": 0.9,  # Diversidad en las respuestas
				"topK": 40  # Variedad de vocabulario
			},
		# Opcional: safetySettings en AI Studio se configuran por cuenta
	}
	try:
		r = _post_with_retry(TEXT_ENDPOINT, headers=headers, body=body, timeout=(10, 30), retries=1)
		if r.status_code != 200:
			logger.warning("Gemini text error %s: %s", r.status_code, r.text[:200])
			return JsonResponse({"answer": f"Informaci√≥n breve sobre {q}: es un animal fascinante que vive en h√°bitats variados."})
		data = r.json()
		candidate = data.get('candidates', [{}])[0]
		parts = candidate.get('content', {}).get('parts', []) or []
		# Unir todos los fragmentos de texto para evitar cortes
		text = ''.join([p.get('text', '') for p in parts]).strip()
		if not text:
			text = f"Informaci√≥n breve sobre {q}: es un animal fascinante que vive en h√°bitats variados."
		return JsonResponse({"answer": text})
	except Exception as e:
		logger.exception("Gemini text exception: %s", e)
		return JsonResponse({"answer": f"Informaci√≥n breve sobre {q}: es un animal fascinante que vive en h√°bitats variados."})


@csrf_exempt
@require_POST
def generate_image(request):
	"""
	Genera im√°genes usando Google Cloud Vertex AI con Imagen 3.
	Requiere credenciales de Google Cloud configuradas.
	"""
	try:
		# Decodificar el body con UTF-8
		body_str = request.body.decode('utf-8') if request.body else '{}'
		body = json.loads(body_str)
	except (json.JSONDecodeError, UnicodeDecodeError) as e:
		logger.error(f"Error decodificando request body: {e}")
		return HttpResponseBadRequest("JSON inv√°lido")
	
	prompt = (body.get('prompt') or '').strip()
	if not prompt:
		return HttpResponseBadRequest("prompt requerido")
	
	# LOG IMPORTANTE: Ver exactamente qu√© prompt llega
	logger.info("="*80)
	logger.info(f"üì• PROMPT RECIBIDO: '{prompt[:300]}...'")
	logger.info("="*80)
	
	# Extraer el nombre del animal del prompt
	# El prompt ahora incluye tanto la pregunta del usuario como la respuesta de Jaggy con contexto
	prompt_lower = prompt.lower()
	
	# Estrategia 1: Buscar el animal directamente con patrones espec√≠ficos
	animal_name = None
	
	# Patrones ordenados por especificidad (m√°s espec√≠ficos primero)
	animal_patterns = [
		# Patr√≥n 1: "un/una [animal]" - el m√°s directo
		r'\b(?:un|una)\s+([a-z√°√©√≠√≥√∫√±√º]+s?)\b',
		# Patr√≥n 2: "el/la/los/las [animal]"
		r'\b(?:el|la|los|las)\s+([a-z√°√©√≠√≥√∫√±√º]+s?)\b',
		# Patr√≥n 3: "de [animal]" o "sobre [animal]"
		r'\b(?:de|del|sobre)\s+(?:un|una|el|la|los|las)?\s*([a-z√°√©√≠√≥√∫√±√º]+s?)\b',
		# Patr√≥n 4: "muestras/mu√©strame [animal]"
		r'\b(?:muestras?|mu√©strame|genera|pinta|dibuja)\s+(?:un|una|el|la|los|las)?\s*([a-z√°√©√≠√≥√∫√±√º]+s?)\b',
	]
	
	for pattern in animal_patterns:
		matches = re.findall(pattern, prompt_lower)
		if matches:
			# Filtrar palabras comunes que NO son animales
			stop_words = {'imagen', 'foto', 'dibujo', 'claro', 'aqu√≠', 'para', 'desde', 
			              'esta', 'este', 'belleza', 'pradera', 'vista', 'libertad', 'viento'}
			
			for candidate in matches:
				candidate = candidate.strip()
				if len(candidate) >= 4 and candidate not in stop_words:
					animal_name = candidate
					logger.info(f"‚úÖ Animal encontrado con patr√≥n '{pattern}': '{animal_name}'")
					break
		
		if animal_name:
			break
	
	# Estrategia 2: An√°lisis de frecuencia (palabras que se repiten = animal de conversaci√≥n)
	if not animal_name or len(animal_name) < 4:
		words = re.findall(r'\b([a-z√°√©√≠√≥√∫√±√º]{4,}s?)\b', prompt_lower)
		word_count = {}
		
		# Lista ampliada de palabras a ignorar
		stop_words = {
			'imagen', 'foto', 'dibujo', 'animal', 'claro', 'aqu√≠', 'tiene', 'hermoso', 
			'belleza', 'quieres', 'saber', 'sobre', 'esta', 'este', 'encantan', 
			'elegantes', 'fuertes', 'sab√≠as', 'pueden', 'desde', 'hasta', 'raza', 
			'razas', 'favorita', 'animales', 'majestuosos', 'super', 'inteligentes',
			'pr√°ctica', 'practico', 'gustar√≠a', 'gustaria', 'compartir', 'estoy',
			'para', 'fascina', 'emocionado', 'admirar', 'admires', 'supuesto'
		}
		
		for word in words:
			if word not in stop_words and len(word) >= 4:
				word_count[word] = word_count.get(word, 0) + 1
		
		# Priorizar palabras que aparecen 2+ veces
		if word_count:
			frequent = {k: v for k, v in word_count.items() if v >= 2}
			if frequent:
				animal_name = max(frequent, key=frequent.get)
				logger.info(f"üîÑ Animal por frecuencia alta: '{animal_name}' ({word_count[animal_name]}x)")
			else:
				animal_name = max(word_count, key=word_count.get)
				logger.info(f"üîÑ Animal por frecuencia: '{animal_name}' ({word_count[animal_name]}x)")
	
	# Estrategia 3: Si no encontr√≥, limpiar el prompt del usuario
	if not animal_name or len(animal_name) < 3:
		cleaned_prompt = prompt_lower
		remove_patterns = [
			r'me\s+(pasas|muestras|generas?|das)\s+(una?\s+)?(imagen|foto|dibujo|ilustraci[o√≥]n)\s+(de|del?)\s+',
			r'quiero\s+(ver|una?\s+imagen\s+de)\s+',
			r'mu[e√©]strame\s+(una?\s+)?(imagen\s+de\s+)?',
			r'genera\s+(una?\s+)?(imagen\s+de\s+)?',
			r'(c[o√≥]mo|como)\s+(se|es)\s+ve\s+',
			r'(imagen|foto|dibujo)\s+de\s+',
			r'^(un|una|el|la|los|las)\s+',
			r'ese\s+animal',
		]
		for pattern in remove_patterns:
			cleaned_prompt = re.sub(pattern, '', cleaned_prompt, flags=re.IGNORECASE)
		
		# Tomar la primera palabra significativa
		words = [w for w in cleaned_prompt.split() if len(w) >= 4]
		if words:
			animal_name = words[0]
	
	# Fallback final: buscar primera palabra significativa
	if not animal_name or len(animal_name) < 4:
		# Buscar sustantivos que parezcan animales (evitando verbos y art√≠culos)
		candidates = re.findall(r'\b([a-z√°√©√≠√≥√∫√±√º]{5,}s?)\b', prompt_lower)
		stop_words_final = {'imagen', 'muestras', 'claro', 'aqu√≠', 'tienes', 'desde', 'pradera'}
		for candidate in candidates:
			if candidate not in stop_words_final:
				animal_name = candidate
				logger.warning(f"‚ö†Ô∏è Animal por fallback: '{animal_name}'")
				break
	
	# √öltima opci√≥n: usar prompt completo truncado
	if not animal_name or len(animal_name) < 4:
		animal_name = prompt[:50]
		logger.error(f"‚ùå No se pudo extraer animal, usando prompt: '{animal_name}'")
	
	logger.info(f"üéØ ANIMAL FINAL: '{animal_name}'")

	
	# Verificar configuraci√≥n de Vertex AI
	project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')
	location = os.environ.get('GOOGLE_CLOUD_LOCATION', 'us-central1')
	credentials_path = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')
	
	if not project_id:
		return JsonResponse({
			"error": "vertex_not_configured",
			"message": "Google Cloud Vertex AI no est√° configurado. Necesitas configurar GOOGLE_CLOUD_PROJECT en el archivo .env"
		}, status=503)
	
	if not credentials_path or not os.path.exists(credentials_path):
		return JsonResponse({
			"error": "credentials_not_found",
			"message": "No se encontraron las credenciales de Google Cloud. Configura GOOGLE_APPLICATION_CREDENTIALS con la ruta al archivo JSON de credenciales."
		}, status=503)
	
	# Verificar que Vertex AI est√© disponible
	if not VERTEX_AI_AVAILABLE:
		return JsonResponse({
			"error": "vertex_not_installed",
			"message": "google-cloud-aiplatform no est√° instalado. Ejecuta: pip install google-cloud-aiplatform"
		}, status=503)
	
	try:
		# Inicializar Vertex AI
		vertexai.init(project=project_id, location=location)
		
		# Diccionario de traducci√≥n espa√±ol -> ingl√©s para animales comunes
		animal_translations = {
			'oso': 'bear', 'osos': 'bear',
			'tigre': 'tiger', 'tigres': 'tiger',
			'le√≥n': 'lion', 'leones': 'lion', 'leon': 'lion',
			'elefante': 'elephant', 'elefantes': 'elephant',
			'jirafa': 'giraffe', 'jirafas': 'giraffe',
			'cebra': 'zebra', 'cebras': 'zebra',
			'perro': 'dog', 'perros': 'dog',
			'gato': 'cat', 'gatos': 'cat',
			'lobo': 'wolf', 'lobos': 'wolf',
			'zorro': 'fox', 'zorros': 'fox',
			'conejo': 'rabbit', 'conejos': 'rabbit',
			'caballo': 'horse', 'caballos': 'horse',
			'panda': 'panda', 'pandas': 'panda',
			'koala': 'koala', 'koalas': 'koala',
			'mono': 'monkey', 'monos': 'monkey',
			'ballena': 'whale', 'ballenas': 'whale',
			'delf√≠n': 'dolphin', 'delfines': 'dolphin', 'delfin': 'dolphin',
			'tibur√≥n': 'shark', 'tiburones': 'shark', 'tiburon': 'shark',
			'√°guila': 'eagle', '√°guilas': 'eagle', 'aguila': 'eagle', 'aguilas': 'eagle',
			'b√∫ho': 'owl', 'b√∫hos': 'owl', 'buho': 'owl', 'buhos': 'owl',
			'loro': 'parrot', 'loros': 'parrot',
			'serpiente': 'snake', 'serpientes': 'snake',
			'cocodrilo': 'crocodile', 'cocodrilos': 'crocodile',
			'tortuga': 'turtle', 'tortugas': 'turtle',
			'ping√ºino': 'penguin', 'ping√ºinos': 'penguin', 'pinguino': 'penguin', 'pinguinos': 'penguin',
			'flamenco': 'flamingo', 'flamencos': 'flamingo',
			'hipop√≥tamo': 'hippopotamus', 'hipop√≥tamos': 'hippopotamus', 'hipopotamo': 'hippopotamus',
			'rinoceronte': 'rhinoceros', 'rinocerontes': 'rhinoceros',
			'canguro': 'kangaroo', 'canguros': 'kangaroo',
			'drag√≥n': 'dragon', 'dragones': 'dragon', 'dragon': 'dragon',
		}
		
		# Traducir el animal al ingl√©s para mejor calidad de imagen
		clean_animal = animal_translations.get(animal_name.lower(), animal_name)
		
		# Prompt MUCHO m√°s espec√≠fico y detallado para Vertex AI Imagen 3
		full_prompt = (
			f"Professional wildlife photograph of a {clean_animal} in its natural habitat. "
			f"High quality National Geographic style. Photorealistic, highly detailed. "
			f"The {clean_animal} is the main subject, centered in frame, facing camera. "
			f"Natural lighting, vivid colors, sharp focus on the animal. "
			f"Blurred background with natural habitat elements (forest, savanna, ocean, etc). "
			f"Suitable for children's educational content. "
			f"No text, no watermarks, no cartoons."
		)
		
		logger.info(f"üìù Prompt para Vertex AI: '{full_prompt}'")
		
		# Obtener modelo
		model_name = os.environ.get('VERTEX_IMAGE_MODEL', 'imagegeneration@006')
		model = ImageGenerationModel.from_pretrained(model_name)
		
		# Generar imagen con par√°metros optimizados para fotograf√≠a realista de animales
		logger.info(f"üé® Generando imagen con Vertex AI: {full_prompt[:100]}...")
		response = model.generate_images(
			prompt=full_prompt,
			number_of_images=1,
			aspect_ratio="1:1",
			safety_filter_level="block_some",
			person_generation="allow_adult",
			# Prompt negativo mejorado para evitar resultados incorrectos
			negative_prompt=(
				"cartoon, anime, drawing, illustration, painting, sketch, "
				"multiple animals, crowd, group, "
				"text, watermark, logo, signature, "
				"scary, frightening, horror, dark, violent, gore, "
				"ugly, deformed, mutation, distorted, blurry, "
				"low quality, low resolution, pixelated, "
				"text, watermark, signature, frame"
			)
		)
		
		# El response es un objeto ImageGenerationResponse
		# Acceder a las im√°genes usando el atributo images
		logger.info(f"Response type: {type(response)}, has images: {hasattr(response, 'images')}")
		if hasattr(response, 'images'):
			logger.info(f"Images count: {len(response.images) if response.images else 0}")
		
		if not response or not hasattr(response, 'images') or not response.images:
			logger.error(f"No images generated. Response: {response}")
			return JsonResponse({
				"error": "no_image_generated",
				"message": "No se pudo generar la imagen. Intenta con otro prompt."
			}, status=500)
		
		# Convertir imagen a base64
		# Obtener la primera imagen generada
		image = response.images[0]
		
		# Intentar obtener la imagen PIL de diferentes formas
		try:
			# M√©todo 1: Atributo privado _pil_image
			pil_image = image._pil_image
		except (AttributeError, Exception) as e:
			logger.warning(f"No se pudo acceder a _pil_image: {e}, intentando _loaded_image")
			try:
				# M√©todo 2: Atributo alternativo
				pil_image = image._loaded_image
			except (AttributeError, Exception) as e2:
				logger.error(f"Tampoco funciona _loaded_image: {e2}")
				# M√©todo 3: Llamar a un m√©todo para cargar la imagen
				pil_image = image._as_pil_image() if hasattr(image, '_as_pil_image') else None
				if not pil_image:
					raise ValueError("No se pudo obtener la imagen PIL del response")
		
		# Convertir a bytes
		buffer = BytesIO()
		pil_image.save(buffer, format='PNG')
		image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
		
		logger.info("Imagen generada exitosamente con Vertex AI")
		
		return JsonResponse({
			"imageBase64": image_base64,
			"mime": "image/png",
			"model": model_name,
			"prompt": animal_name  # Retornar el nombre limpio del animal
		})
	
	except Exception as e:
		logger.error(f"‚ùå Error generando imagen con Vertex AI: {str(e)}")
		return JsonResponse({
			"error": "image_generation_failed",
			"message": f"Error al generar la imagen: {str(e)}"
		}, status=500)


@csrf_exempt
@require_POST
def text_to_speech(request):
	"""
	Endpoint para convertir texto a voz usando Google Cloud Text-to-Speech.
	
	Body JSON:
	{
		"text": "Texto a convertir en voz",
		"languageCode": "es-US" (opcional, default: "es-US"),
		"voiceName": "es-US-Neural2-B" (opcional, voz por defecto si no se especifica),
		"pitch": 0 (opcional, rango: -20.0 a 20.0),
		"speakingRate": 1.0 (opcional, rango: 0.25 a 4.0)
	}
	
	Retorna:
	{
		"audioContent": "base64_encoded_audio",
		"mime": "audio/mp3"
	}
	"""
	if not TEXT_TO_SPEECH_AVAILABLE:
		return JsonResponse({
			"error": "Text-to-Speech no disponible",
			"message": "La biblioteca google-cloud-texttospeech no est√° instalada."
		}, status=500)
	
	try:
		data = json.loads(request.body.decode('utf-8'))
	except json.JSONDecodeError:
		return HttpResponseBadRequest("JSON inv√°lido")
	
	text = data.get('text', '').strip()
	if not text:
		return HttpResponseBadRequest("El campo 'text' es requerido")
	
	# Limpiar emojis del texto (opcional, ya que TTS no los lee bien)
	import re
	text_clean = re.sub(r'[^\w\s\.,;:¬ø?¬°!√°√©√≠√≥√∫√±√Å√â√ç√ì√ö√ë-]', '', text)
	
	# Configuraci√≥n de voz
	language_code = data.get('languageCode', 'es-US')
	voice_name = data.get('voiceName', 'es-US-Neural2-B')  # Voz masculina joven por defecto
	pitch = data.get('pitch', 5.0)  # M√°s agudo para Bob Esponja
	speaking_rate = data.get('speakingRate', 1.2)  # M√°s r√°pido para energ√≠a
	
	logger.info(f"üé§ Generando audio para: '{text_clean[:50]}...'")
	logger.info(f"üéµ Voz: {voice_name}, pitch: {pitch}, rate: {speaking_rate}")
	
	try:
		# Inicializar cliente de Text-to-Speech
		client = texttospeech.TextToSpeechClient()
		
		# Configurar la entrada de texto
		synthesis_input = texttospeech.SynthesisInput(text=text_clean)
		
		# Configurar la voz
		voice = texttospeech.VoiceSelectionParams(
			language_code=language_code,
			name=voice_name
		)
		
		# Configurar par√°metros de audio
		audio_config = texttospeech.AudioConfig(
			audio_encoding=texttospeech.AudioEncoding.MP3,
			pitch=pitch,
			speaking_rate=speaking_rate
		)
		
		# Generar el audio
		response = client.synthesize_speech(
			input=synthesis_input,
			voice=voice,
			audio_config=audio_config
		)
		
		# Convertir audio a base64
		audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
		
		logger.info("‚úÖ Audio generado exitosamente con Google Cloud Text-to-Speech")
		
		return JsonResponse({
			"audioContent": audio_base64,
			"mime": "audio/mp3",
			"voice": voice_name,
			"text": text_clean
		})
		
	except Exception as e:
		logger.error(f"‚ùå Error generando audio: {str(e)}")
		return JsonResponse({
			"error": "Error generando audio",
			"message": str(e)
		}, status=500)
		
	except Exception as e:
		logger.exception("Error generando imagen con Vertex AI: %s", e)
		return JsonResponse({
			"error": "generation_error",
			"message": f"Error al generar la imagen: {str(e)}"
		}, status=500)
